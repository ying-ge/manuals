[
  {
    "title": "Deep Learning for Early Detection of Alzheimer's Disease from Brain MRI",
    "authors": [
      "Zhang L",
      "Wang M",
      "Chen Y"
    ],
    "corresponding_author": "Zhang L",
    "affiliations": [
      "Stanford University School of Medicine"
    ],
    "abstract": "\nBackground: Early detection of Alzheimer's disease (AD) remains a critical challenge in neurology.\nWe developed a deep learning model to predict AD onset from structural brain MRI scans.\n\nMethods: We trained a 3D convolutional neural network (CNN) on 5,247 MRI scans from the \nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. The model was designed to classify\npatients into three categories: cognitively normal, mild cognitive impairment, and AD.\nWe used ResNet-50 architecture with transfer learning and data augmentation techniques.\n\nResults: The deep learning model achieved 92.3% accuracy, with an AUC-ROC of 0.96 on the \nindependent test set. Sensitivity was 89.7% and specificity was 94.1%. The model outperformed \ntraditional radiological assessment by 12 percentage points.\n\nConclusions: Our AI-powered diagnostic tool demonstrates superior performance in early AD \ndetection and could assist clinicians in identifying at-risk patients for early intervention.\n        ",
    "url": "https://www.medrxiv.org/content/10.1101/2024.01.15.24301234",
    "published_at": "2024-01-15T00:00:00",
    "source": "medrxiv_demo",
    "what_done": "Early detection of Alzheimer's disease (AD) remains a critical challenge in neurology",
    "ai_role": "Background: Early detection of Alzheimer's disease (AD) remains a critical challenge in neurology",
    "models": "CNN, ResNet",
    "data_sources": "",
    "metrics": "accuracy, AUC, ROC, sensitivity, specificity",
    "needs_manual_review": true
  },
  {
    "title": "Machine Learning for Predicting COVID-19 Severity Using Clinical and Laboratory Data",
    "authors": [
      "Smith J",
      "Johnson K",
      "Brown R"
    ],
    "corresponding_author": "Smith J",
    "affiliations": [
      "Massachusetts General Hospital",
      "Harvard Medical School"
    ],
    "abstract": "\nObjective: To develop and validate a machine learning model for predicting severe COVID-19 \noutcomes using readily available clinical and laboratory parameters.\n\nMethods: This retrospective study included 3,892 COVID-19 patients from 15 hospitals. We \nevaluated multiple machine learning algorithms including random forest, gradient boosting \n(XGBoost), and logistic regression. Input features included age, comorbidities, vital signs,\nand laboratory values (D-dimer, CRP, lymphocyte count). The primary outcome was ICU admission\nor death within 30 days.\n\nResults: The XGBoost model achieved the best performance with an AUROC of 0.88 (95% CI: 0.86-0.90).\nThe model identified D-dimer >1000 ng/mL, age >65 years, and lymphopenia as the strongest \npredictors. External validation on 1,200 patients from 5 independent centers showed consistent\nperformance (AUROC 0.85).\n\nConclusions: Machine learning can accurately predict COVID-19 severity using routine clinical\ndata, potentially enabling early risk stratification and resource allocation.\n        ",
    "url": "https://www.medrxiv.org/content/10.1101/2024.02.03.24302156",
    "published_at": "2024-02-03T00:00:00",
    "source": "medrxiv_demo",
    "what_done": "evaluated multiple machine learning algorithms including random forest, gradient boosting \n(XGBoost), and logistic regression",
    "ai_role": "Objective: To develop and validate a machine learning model for predicting severe COVID-19 \noutcomes using readily available clinical and laboratory parameters",
    "models": "random forest, gradient boosting, logistic regression, XGBoost",
    "data_sources": "",
    "metrics": "ROC, AUROC, performance",
    "needs_manual_review": true
  },
  {
    "title": "Artificial Intelligence for Automated Diabetic Retinopathy Screening in Primary Care",
    "authors": [
      "Lee S",
      "Park J",
      "Kim H",
      "Choi M"
    ],
    "corresponding_author": "Lee S",
    "affiliations": [
      "Seoul National University Hospital"
    ],
    "abstract": "\nBackground: Diabetic retinopathy (DR) is a leading cause of blindness, but screening rates \nremain low. We developed an AI system for automated DR screening in primary care settings.\n\nMethods: We trained a deep neural network on 85,000 fundus photographs from 25,000 patients.\nThe model used EfficientNet-B5 architecture to classify images into five categories: no DR,\nmild, moderate, severe non-proliferative DR, and proliferative DR. We evaluated the system\nin a prospective real-world deployment across 120 primary care clinics.\n\nResults: The AI system achieved 94.5% sensitivity and 91.2% specificity for referable DR\n(moderate or worse). Agreement with expert ophthalmologists was substantial (kappa=0.89).\nIn the real-world deployment, screening rates increased from 45% to 78%, and the median\ntime from screening to treatment decreased from 63 to 18 days.\n\nConclusions: AI-powered automated screening can improve DR detection rates and accelerate\ntreatment in primary care, potentially preventing vision loss in diabetic patients.\n        ",
    "url": "https://www.medrxiv.org/content/10.1101/2024.03.10.24303987",
    "published_at": "2024-03-10T00:00:00",
    "source": "medrxiv_demo",
    "what_done": "Diabetic retinopathy (DR) is a leading cause of blindness, but screening rates \nremain low",
    "ai_role": "Background: Diabetic retinopathy (DR) is a leading cause of blindness, but screening rates \nremain low",
    "models": "EfficientNet",
    "data_sources": "",
    "metrics": "sensitivity, specificity",
    "needs_manual_review": true
  },
  {
    "title": "Natural Language Processing for Automated Clinical Trial Eligibility Screening",
    "authors": [
      "Rodriguez A",
      "Martinez C",
      "Garcia F"
    ],
    "corresponding_author": "Rodriguez A",
    "affiliations": [
      "Mayo Clinic",
      "University of Arizona"
    ],
    "abstract": "\nPurpose: Clinical trial recruitment is time-consuming and inefficient. We developed a natural\nlanguage processing (NLP) system to automatically screen electronic health records (EHRs) for\ntrial eligibility.\n\nMethods: Using BERT-based transformer models, we created an NLP pipeline to extract medical\nconcepts from unstructured clinical notes. The system matched patient data against trial\ninclusion/exclusion criteria for 50 oncology trials. We processed EHRs from 15,000 patients\nand compared AI recommendations with manual screening by clinical research coordinators.\n\nResults: The NLP system achieved 87% precision and 92% recall for identifying eligible patients.\nProcessing time was reduced from 20 minutes per patient (manual) to 30 seconds (automated).\nThe system successfully identified 340 eligible patients who were not found through conventional\nmethods. Implementation led to a 45% increase in trial enrollment rates.\n\nConclusions: AI-driven NLP can dramatically improve clinical trial recruitment efficiency and\nhelp identify more eligible candidates from existing patient populations.\n        ",
    "url": "https://www.medrxiv.org/content/10.1101/2024.04.22.24305432",
    "published_at": "2024-04-22T00:00:00",
    "source": "medrxiv_demo",
    "what_done": "processed EHRs from 15,000 patients\nand compared AI recommendations with manual screening by clinical research coordinators",
    "ai_role": "Methods: Using BERT-based transformer models, we created an NLP pipeline to extract medical\nconcepts from unstructured clinical notes",
    "models": "BERT",
    "data_sources": "",
    "metrics": "precision, recall, ROC",
    "needs_manual_review": true
  },
  {
    "title": "Federated Learning for Privacy-Preserving Medical Image Analysis Across Institutions",
    "authors": [
      "Chen W",
      "Liu X",
      "Zhang Q",
      "Wu Y"
    ],
    "corresponding_author": "Chen W",
    "affiliations": [
      "Stanford University",
      "MIT"
    ],
    "abstract": "\nBackground: Multi-institutional collaboration in medical AI is limited by data privacy concerns.\nWe implemented a federated learning framework for training medical image classifiers without\nsharing patient data.\n\nMethods: We deployed federated learning across 8 hospitals for breast cancer detection in\nmammography. Each site trained a local ResNet-101 model on their private data (total 125,000\nimages), and only model parameters were shared centrally. We compared federated learning with\ncentralized training and single-institution models.\n\nResults: The federated model achieved 91.8% AUC, comparable to centralized training (92.1% AUC)\nand significantly better than average single-institution performance (85.3% AUC). The approach\nmaintained HIPAA compliance and preserved local data governance. Training time was 2.3x longer\nthan centralized but enabled participation from institutions with data sharing restrictions.\n\nConclusions: Federated learning enables collaborative AI development while preserving patient\nprivacy, offering a viable path for multi-institutional medical AI research.\n        ",
    "url": "https://www.medrxiv.org/content/10.1101/2024.05.15.24307123",
    "published_at": "2024-05-15T00:00:00",
    "source": "medrxiv_demo",
    "what_done": "Multi-institutional collaboration in medical AI is limited by data privacy concerns",
    "ai_role": "Background: Multi-institutional collaboration in medical AI is limited by data privacy concerns",
    "models": "ResNet",
    "data_sources": "",
    "metrics": "AUC, performance",
    "needs_manual_review": true
  }
]